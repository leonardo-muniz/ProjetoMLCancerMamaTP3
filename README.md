# Classifica√ß√£o de C√¢ncer de Mama: Comparativo de Modelos KNN e Regress√£o Log√≠stica

## üìù Vis√£o Geral do Projeto

Este projeto tem como objetivo principal desenvolver e comparar modelos de classifica√ß√£o para o diagn√≥stico de c√¢ncer de mama, utilizando o famoso dataset Breast Cancer Wisconsin. O foco est√° em avaliar o desempenho de dois algoritmos ‚Äì K-Nearest Neighbors (KNN) como modelo baseline e Regress√£o Log√≠stica como um novo modelo comparativo ‚Äì sob condi√ß√µes controladas, incluindo a simula√ß√£o de ru√≠do nos dados.

A an√°lise segue uma metodologia rigorosa de avalia√ß√£o, combinando a estrat√©gia de holdout com valida√ß√£o cruzada para garantir a robustez das m√©tricas de desempenho. Ao final, discutimos qual modelo se mostrou mais adequado para a tarefa, considerando m√©tricas cr√≠ticas para um contexto m√©dico.

## üìä Dataset

O projeto utiliza o dataset Breast Cancer Wisconsin (Diagnostic), dispon√≠vel no scikit-learn. Este conjunto de dados cont√©m caracter√≠sticas computadas a partir de uma imagem digitalizada de um aspirado por agulha fina (FNA) de uma massa mam√°ria. O objetivo √© classificar se a massa √© maligna (cancerosa) ou benigna (n√£o cancerosa).

## üß† Modelos Implementados

1 ) K-Nearest Neighbors (KNN)

  - Um classificador baseado na proximidade dos "vizinhos" mais pr√≥ximos.

  - Utilizado como o nosso baseline de compara√ß√£o.

2 ) Regress√£o Log√≠stica

  - Um modelo linear generalizado, robusto e interpret√°vel para problemas de classifica√ß√£o bin√°ria.

  - Implementado como o novo modelo para compara√ß√£o.

## ‚öôÔ∏è Metodologia de Avalia√ß√£o

Para garantir uma avalia√ß√£o justa e robusta dos modelos, adotei a seguinte metodologia:

1 ) Pr√©-processamento de Dados:
   
Todos os dados foram padronizados usando StandardScaler para garantir que as features estivessem na mesma escala, o que √© crucial para modelos baseados em dist√¢ncia como o KNN.

2 ) Introdu√ß√£o de Ru√≠do:

Para simular condi√ß√µes do mundo real e testar a robustez dos modelos, adicionei um termo de ru√≠do gaussiano (distribui√ß√£o normal) aos dados padronizados. Isso permite avaliar o desempenho dos algoritmos em cen√°rios com imperfei√ß√µes nos dados.

3 ) Estrat√©gia de Holdout + Valida√ß√£o Cruzada:

O dataset foi dividido inicialmente em conjuntos de treino (70%) e teste (30%) usando a estrat√©gia de holdout. Uma random_state (semente aleat√≥ria) espec√≠fica foi definida para garantir a reprodutibilidade dessa divis√£o. A mesma best_seed encontrada no TP2 (para o KNN sem ru√≠do) foi usada para todas as divis√µes principais, assegurando uma compara√ß√£o justa entre os modelos.

Dentro do conjunto de treino, utilizei a Valida√ß√£o Cruzada Estratificada (StratifiedKFold com 10 folds) em conjunto com GridSearchCV para encontrar os melhores hiperpar√¢metros (o k ideal para KNN e o C ideal para Regress√£o Log√≠stica). Isso minimiza o vi√©s de uma √∫nica divis√£o de dados e garante que a propor√ß√£o das classes seja mantida em cada fold.

4 ) Re-treinamento Final:

Ap√≥s identificar os melhores hiperpar√¢metros atrav√©s da valida√ß√£o cruzada, cada modelo foi re-treinado utilizando o conjunto completo de treino e esses hiperpar√¢metros otimizados.

5 ) M√©tricas de Avalia√ß√£o:

  - A performance final de cada modelo (com e sem ru√≠do, ap√≥s o re-treinamento) foi avaliada no conjunto de teste (n√£o visto) usando as seguintes m√©tricas:
    - Acur√°cia: Propor√ß√£o de previs√µes corretas.
    - Precis√£o (Precision): Quantas das previs√µes positivas estavam corretas.
    - Recall (Sensibilidade): Quantas das amostras positivas reais foram corretamente identificadas.
    - F1-score: M√©dia harm√¥nica de Precis√£o e Recall, √∫til para balancear ambas as m√©tricas.
   
## üíª Como Rodar o C√≥digo

### Para executar a an√°lise e replicar os resultados, siga os passos abaixo:

Pr√©-requisitos

- Certifique-se de ter o Python instalado (preferencialmente vers√£o 3.7+). 

- As bibliotecas necess√°rias est√£o listadas no arquivo requirements.txt.

1 ) Crie e ative um ambiente virtual (recomendado):

``` python -m venv venv ```

#### No Windows
```.\venv\Scripts\activate```

#### No macOS/Linux
```source venv/bin/activate```

2 ) Instale as depend√™ncias a partir do requirements.txt:

```pip install -r requirements.txt```

3 ) Instale o Jupyter Notebook dentro do seu ambiente virtual:

```pip install jupyter```

4 ) Selecione o ambiente criado para o Jupyter Notebook:

Ap√≥s instalar o Jupyter, voc√™ precisa garantir que ele reconhe√ßa o kernel do seu ambiente virtual.

1. Inicie o Jupyter Notebook:

```jupyter notebook```

2. No seu navegador, o Jupyter abrir√°. Navegue at√© o diret√≥rio onde seu .ipynb (arquivo do notebook) est√° localizado.
3. Ao abrir um notebook existente ou criar um novo, v√° em Kernel (ou "N√∫cleo" em portugu√™s) no menu superior, depois Change Kernel (ou "Mudar N√∫cleo") e selecione o ambiente venv que voc√™ criou. Ele geralmente aparecer√° com o nome do seu ambiente (e.g., Python (venv)).

Alternativamente, se voc√™ usa VS Code, o processo √© ainda mais simples:

1. Abra a pasta do seu projeto no VS Code.
2. Abra o arquivo .ipynb.
3. No canto superior direito da janela do notebook, clique em "Select Kernel" (ou no √≠cone de uma setinha para baixo).
4. Selecione a op√ß√£o "Python Environments..." (ou "Ambientes Python...") e escolha o ambiente venv que voc√™ criou. O VS Code automaticamente configurar√° o kernel para voc√™.

5 ) Execute o Jupyter Notebook:

Com o kernel correto selecionado, voc√™ pode rodar as c√©lulas do seu notebook para ver a an√°lise e os resultados.
